<!doctype html>
<html itemscope lang="en-us" itemtype="http://schema.org/WebPage">

<head>
    <meta charset="utf-8">
    <title>MedUnifier: Unifying Vision-and-Language Pre-training on Medical Data</title>
    <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5">
    <meta name="theme-name" content="hugoplate">
    <link rel="shortcut icon" href="../imgs/logo_hu1e0a0ed9ef631b29b11507eedded13fb_83803_96x0_resize_lanczos_3.png" type="image/x-icon">
    <link rel="icon" href="../imgs/logo_hu1e0a0ed9ef631b29b11507eedded13fb_83803_96x0_resize_lanczos_3.png" type="image/x-icon">
    <base href="https://medvisailab.github.io/pblctns/">

    <meta name="description" content="MedUnifier: A novel framework unifying vision-and-language pre-training on medical data with vision generation task using discrete visual representations">
    <meta name="keywords" content="Computer Vision, Medical AI, Vision-Language Pre-training, Medical Imaging, Deep Learning">
    <meta name="author" content="MedVisAI Lab">

    <!-- Open Graph -->
    <meta property="og:title" content="MedUnifier: Unifying Vision-and-Language Pre-training on Medical Data">
    <meta property="og:description" content="A novel framework unifying vision-and-language pre-training on medical data with vision generation task using discrete visual representations">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://medvisailab.github.io/pblctns/medunifier.html">

    <!-- Twitter Card -->
    <meta name="twitter:title" content="MedUnifier: Unifying Vision-and-Language Pre-training on Medical Data">
    <meta name="twitter:description" content="A novel framework unifying vision-and-language pre-training on medical data with vision generation task using discrete visual representations">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Heebo:wght@400;600&family=Signika:wght@500;700&display=swap" rel="stylesheet">

    <!-- CSS -->
    <link href="../css/style.min.80b93bb3a795f7194d0ca0c445309f1547c3c019264bfd28165ca93c97401b5d.css" rel="stylesheet">
    <link href="../css/mvait-enhancements.css" rel="stylesheet">
    <link href="../css/theme-fixes.css" rel="stylesheet">

    <style>
        .project-page {
            max-width: 1000px;
            margin: 0 auto;
            padding: 2rem;
            line-height: 1.6;
        }

        .project-title {
            font-size: 2.5rem;
            font-weight: 700;
            text-align: center;
            margin-bottom: 1.5rem;
            color: #2c3e50;
        }

        .dark .project-title {
            color: #ecf0f1;
        }

        .authors {
            text-align: center;
            font-size: 1.1rem;
            margin-bottom: 2rem;
            color: #34495e;
        }

        .dark .authors {
            color: #bdc3c7;
        }

        .author-name {
            margin: 0 0.5rem;
        }

        .affiliation {
            font-style: italic;
            color: #7f8c8d;
            margin-top: 0.5rem;
        }

        .dark .affiliation {
            color: #95a5a6;
        }

        .links {
            text-align: center;
            margin: 2rem 0;
        }

        .link-btn {
            display: inline-block;
            padding: 0.75rem 1.5rem;
            margin: 0.5rem;
            background: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 0.5rem;
            transition: background 0.3s ease;
            font-weight: 600;
        }

        .link-btn:hover {
            background: #2980b9;
            color: white;
        }

        .link-btn.arxiv {
            background: #e74c3c;
        }

        .link-btn.arxiv:hover {
            background: #c0392b;
        }

        .link-btn.video {
            background: #9b59b6;
        }

        .link-btn.video:hover {
            background: #8e44ad;
        }

        .section-title {
            font-size: 1.8rem;
            font-weight: 600;
            margin: 2.5rem 0 1rem 0;
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 0.5rem;
        }

        .dark .section-title {
            color: #ecf0f1;
        }

        .abstract, .method-section, .results-section {
            margin-bottom: 2rem;
            text-align: justify;
        }

        .method-figure, .results-figure {
            text-align: center;
            margin: 2rem 0;
        }

        .method-figure img, .results-figure img {
            max-width: 100%;
            height: auto;
            border-radius: 0.5rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        .figure-caption {
            font-style: italic;
            color: #7f8c8d;
            margin-top: 0.5rem;
            font-size: 0.95rem;
        }

        .dark .figure-caption {
            color: #95a5a6;
        }

        .highlight {
            background: linear-gradient(120deg, #a8e6cf 0%, #dcedc1 100%);
            padding: 0.2rem 0.4rem;
            border-radius: 0.25rem;
            font-weight: 600;
        }

        .dark .highlight {
            background: linear-gradient(120deg, #2c3e50 0%, #34495e 100%);
            color: #ecf0f1;
        }

        .citation-box {
            background: #f8f9fa !important;
        }

        .dark .citation-box {
            background: #2c3e50 !important;
        }

        .citation-box pre {
            color: #000 !important;
        }

        .dark .citation-box pre {
            color: #ecf0f1 !important;
        }

        .contributions {
            background: #f8f9fa;
            padding: 1.5rem;
            border-radius: 0.5rem;
            border-left: 4px solid #3498db;
            margin: 1.5rem 0;
        }

        .dark .contributions {
            background: #2c3e50;
            color: #ecf0f1;
        }

        .contributions ul {
            margin: 0;
            padding-left: 1.5rem;
        }

        .contributions li {
            margin-bottom: 0.5rem;
        }

        @media (max-width: 768px) {
            .project-page {
                padding: 1rem;
            }

            .project-title {
                font-size: 2rem;
            }

            .link-btn {
                display: block;
                margin: 0.5rem auto;
                max-width: 200px;
            }
        }
    </style>
</head>

<body>
    <header class="header sticky top-0 z-30">
        <nav class="navbar container">
            <div class="order-0">
                <a class="navbar-brand block" href="../">
                    <img fetchpriority="high" decoding="async" class="img logo-light" width="160" height="32"
                        src="../imgs/logo_hu1e0a0ed9ef631b29b11507eedded13fb_83803_320x0_resize_q90_h2_lanczos_3.webp"
                        alt="MedVisAITechnologies"
                        onerror='this.onerror=null,this.src="../imgs/logo_hu1e0a0ed9ef631b29b11507eedded13fb_83803_320x0_resize_lanczos_3.png"'>
                    <img fetchpriority="high" decoding="async" class="img logo-dark" width="160" height="32"
                        src="../imgs/logo_hu1e0a0ed9ef631b29b11507eedded13fb_83803_320x0_resize_q90_h2_lanczos_3.webp"
                        alt="MedVisAITechnologies"
                        onerror='this.onerror=null,this.src="../imgs/logo_hu1e0a0ed9ef631b29b11507eedded13fb_83803_320x0_resize_lanczos_3.png"'>
                </a>
            </div>

            <input id="nav-toggle" type="checkbox" class="hidden">
            <label id="show-button" for="nav-toggle" class="order-2 flex cursor-pointer items-center md:order-1 md:hidden">
                <svg class="h-6 fill-current" viewBox="0 0 20 20">
                    <title>Menu Open</title>
                    <path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0V0z" />
                </svg>
            </label>

            <label id="hide-button" for="nav-toggle" class="order-2 hidden cursor-pointer items-center md:order-1">
                <svg class="h-6 fill-current" viewBox="0 0 20 20">
                    <title>Menu Close</title>
                    <polygon points="11 9 22 9 22 11 11 11 11 22 9 22 9 11 -2 11 -2 9 9 9 9 -2 11 -2" transform="rotate(45 10 10)" />
                </svg>
            </label>

            <ul id="nav-menu" class="navbar-nav order-3 hidden w-full pb-6 lg:order-1 lg:flex lg:w-auto lg:space-x-2 lg:pb-0 xl:space-x-8">
                <li class="nav-item"><a class="nav-link" href="../">MVAIT</a></li>
                <li class="nav-item"><a class="nav-link" href="../team">Team</a></li>
                <li class="nav-item"><a class="nav-link" href="../research/">Research</a></li>
                <li class="nav-item"><a class="nav-link" href="../projects">Project Funding</a></li>
                <li class="nav-item"><a class="nav-link" href="../pos/">Positions</a></li>
                <li class="nav-item"><a class="nav-link" href="../pblctns">Publications</a></li>
                <li class="mt-4 inline-block lg:hidden"><a class="btn btn-outline-primary btn-sm" href="../eml">Contact</a></li>
            </ul>

            <div class="order-1 ml-auto flex items-center md:order-2 lg:ml-0">
                <div class="theme-switcher mr-5">
                    <input id="theme-switcher" data-theme-switcher type="checkbox">
                    <label for="theme-switcher">
                        <span class="sr-only">theme switcher</span>
                        <span>
                            <svg class="absolute left-[4px] top-[4px] z-10 opacity-100 dark:opacity-0" viewBox="0 0 56 56" fill="#fff" height="16" width="16">
                                <path d="M30 4.6c0-1-.9-2-2-2a2 2 0 00-2 2v5c0 1 .9 2 2 2s2-1 2-2zm9.6 9a2 2 0 000 2.8c.8.8 2 .8 2.9.0L46 13a2 2 0 000-2.9 2 2 0 00-3 0zm-26 2.8c.7.8 2 .8 2.8.0.8-.7.8-2 0-2.9L13 10c-.7-.7-2-.8-2.9.0-.7.8-.7 2.1.0 3zM28 16A12 12 0 0016 28a12 12 0 0012 12 12 12 0 0012-12A12 12 0 0028 16zm23.3 14c1.1.0 2-.9 2-2s-.9-2-2-2h-4.9a2 2 0 00-2 2c0 1.1 1 2 2 2zM4.7 26a2 2 0 00-2 2c0 1.1.9 2 2 2h4.9c1 0 2-.9 2-2s-1-2-2-2zm37.8 13.6a2 2 0 00-3 0 2 2 0 000 2.9l3.6 3.5a2 2 0 002.9.0c.8-.8.8-2.1.0-3zM10 43.1a2 2 0 000 2.9c.8.7 2.1.8 3 0l3.4-3.5c.8-.8.8-2.1.0-2.9s-2-.8-2.9.0zm20 3.4c0-1.1-.9-2-2-2a2 2 0 00-2 2v4.9c0 1 .9 2 2 2s2-1 2-2z" />
                            </svg>
                            <svg class="absolute left-[4px] top-[4px] z-10 opacity-0 dark:opacity-100" viewBox="0 0 24 24" fill="none" height="16" width="16">
                                <path fill="#000" fill-rule="evenodd" clip-rule="evenodd" d="M8.2 2.2c1-.4 2 .6 1.6 1.5-1 3-.4 6.4 1.8 8.7a8.4 8.4.0 008.7 1.8c1-.3 2 .5 1.5 1.5v.1A10.3 10.3.0 0112.4 22 10.3 10.3.0 013.2 6.7c1-2 2.9-3.5 4.9-4.4z" />
                            </svg>
                        </span>
                    </label>
                </div>
                <script>
                    var themeSwitch, darkMode = !0;
                    localStorage.getItem("theme") === "dark" ? darkMode = !0 : localStorage.getItem("theme") === "light" && (darkMode = !1);
                    darkMode && document.documentElement.classList.toggle("dark");
                    themeSwitch = document.querySelectorAll("[data-theme-switcher]");
                    document.addEventListener("DOMContentLoaded", () => {
                        [].forEach.call(themeSwitch, function (e) {
                            e.checked = !!darkMode;
                            e.addEventListener("click", () => {
                                document.documentElement.classList.toggle("dark");
                                localStorage.setItem("theme", document.documentElement.classList.contains("dark") ? "dark" : "light")
                            })
                        })
                    });
                </script>
                <a href="../eml" class="btn btn-outline-primary btn-sm hidden lg:inline-block">Contact</a>
            </div>
        </nav>
    </header>

    <main>
        <div class="project-page">
            <h1 class="project-title">
                MedUnifier: Unifying Vision-and-Language Pre-training on Medical Data with Vision Generation Task using Discrete Visual Representations
            </h1>

            <div class="authors">
                <div style="margin-bottom: 1rem;">
                    <span class="author-name">Ziyang Zhang<sup>1,2</sup></span>
                    <span class="author-name">Yang Yu<sup>3</sup></span>
                    <span class="author-name">Yucheng Chen<sup>1,4</sup></span>
                    <span class="author-name">Xulei Yang<sup>3</sup><sup style="font-size: 0.7em;">(âœ‰)</sup></span>
                    <span class="author-name">Si Yong Yeo<sup>1,4</sup><sup style="font-size: 0.7em;">(âœ‰)</sup></span>
                </div>

                <div class="affiliation">
                    <sup>1</sup>MedVisAI Lab<br>
                    <sup>2</sup>ECE, Northwestern University<br>
                    <sup>3</sup>Institute for Infocomm Research (I2R), A*STAR, Singapore<br>
                    <sup>4</sup>Lee Kong Chian School of Medicine, Nanyang Technological University
                </div>
                <div style="text-align: center; margin-top: 0.5rem; font-style: italic; color: #7f8c8d; font-size: 0.9rem;">
                    <sup style="font-size: 0.8em;">(âœ‰)</sup> Corresponding authors
                </div>
            </div>

            <div class="links">
                <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_MedUnifier_Unifying_Vision-and-Language_Pre-training_on_Medical_Data_with_Vision_Generation_CVPR_2025_paper.pdf" class="link-btn" target="_blank">ðŸ“„ CVPR 2025 Paper</a>
                <a href="https://arxiv.org/abs/2503.01019" class="link-btn arxiv" target="_blank">ðŸ“š arXiv</a>
                <a href="https://github.com/ZiyangZhang0511/MedUnifier" class="link-btn" target="_blank">ðŸ’» Code</a>
                <a href="https://physionet.org/content/mimic-cxr/2.0.0/" class="link-btn" target="_blank">ðŸ“Š Data</a>
                <a href="https://www.youtube.com/watch?v=Bw1Aj4cJ5rw" class="link-btn video" target="_blank">ðŸŽ¥ Video</a>
            </div>

            <!-- Embedded Video -->
            <div style="text-align: center; margin: 2rem 0;">
                <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; background: #000; border-radius: 0.5rem;">
                    <iframe
                        src="https://www.youtube.com/embed/Bw1Aj4cJ5rw"
                        style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;"
                        allowfullscreen
                        title="MedUnifier Video Presentation">
                    </iframe>
                </div>
                <div style="margin-top: 0.5rem; color: #7f8c8d; font-style: italic;">
                    Video presentation of MedUnifier framework and results
                </div>
            </div>

            <h2 class="section-title">Abstract</h2>
            <div class="abstract">
                <p>Current <span class="highlight">Vision-Language Pre-training (VLP)</span> approaches in the medical domain primarily focus on feature extraction and cross-modal comprehension, with limited attention to generating or transforming visual content. This gap restricts the development of comprehensive multi-modal models that can both understand and create medical visual content.</p>

                <p>We propose <span class="highlight">MedUnifier</span>, a novel framework that seamlessly integrates text-grounded image generation capabilities with multi-modal learning strategies for medical data. Our approach employs <span class="highlight">visual vector quantization</span> for cross-modal learning, enabling more comprehensive multi-modal alignment through discrete visual representations.</p>

                <p>MedUnifier demonstrates superior performance across uni-modal, cross-modal, and multi-modal tasks, showing its ability to generate realistic medical images and reports while maintaining strong understanding capabilities across diverse medical imaging modalities.</p>
            </div>

            <h2 class="section-title">Key Contributions</h2>
            <div class="contributions">
                <ul>
                    <li><strong>Novel Med-VLP Framework:</strong> First to unify vision-language pre-training with language-guided visual generation in the medical domain</li>
                    <li><strong>Text-Grounded Image Generation (TIG):</strong> Innovative module designed to capture detailed medical image information through discrete visual representations</li>
                    <li><strong>Comprehensive Evaluation:</strong> Demonstrated superior performance across uni-modal, cross-modal, and multi-modal medical tasks</li>
                    <li><strong>Discrete Visual Representations:</strong> Novel use of vector quantization to enable more effective cross-modal alignment in medical imaging</li>
                </ul>
            </div>

            <h2 class="section-title">Method Overview</h2>
            <div class="method-section">
                <p>MedUnifier employs a <span class="highlight">transformer-based architecture</span> with learnable embeddings and incorporates four key learning objectives:</p>

                <ul style="margin: 1rem 0; padding-left: 2rem;">
                    <li><strong>Image-Text Contrastive Learning (ITC):</strong> Aligns visual and textual representations in a shared embedding space</li>
                    <li><strong>Image-Text Matching (ITM):</strong> Enables fine-grained understanding of image-text correspondence</li>
                    <li><strong>Image-Text Generation (ITG):</strong> Generates descriptive medical reports from visual input</li>
                    <li><strong>Text-Grounded Image Generation (TIG):</strong> Novel capability to generate medical images from textual descriptions</li>
                </ul>

                <p>The framework utilizes <span class="highlight">vector quantization</span> to learn discrete visual representations, which facilitates more effective cross-modal alignment and enables the generation of high-quality medical images guided by textual descriptions.</p>
            </div>

            <!-- Method figure -->
            <div class="method-figure">
                <img src="imgs/MedUnifier-Figure 1.png" alt="MedUnifier Framework Architecture" style="max-width: 50%; height: auto; border-radius: 0.5rem; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); display: block; margin: 0 auto;">
                <div class="figure-caption">
                    <strong>Figure 1.</strong> Our MedUnifier framework incorporates learnable embeddings to enable multi-modal interactions. The red components focus on the initial extraction of visual features and the reconstruction of medical images. The green elements are dedicated to the modelling and interpretation of medical reports. Meanwhile, the blue components apply a range of attention-masking strategies to achieve a comprehensive fusion of image and text representations.
                </div>
            </div>

            <!-- Detailed architecture figure -->
            <div class="method-figure">
                <img src="imgs/MedUnifier-Figure 2.png" alt="MedUnifier Model Architecture and Learning Objectives" style="max-width: 100%; height: auto; border-radius: 0.5rem; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
                <div class="figure-caption">
                    <strong>Figure 2.</strong> Left: model architecture consists of an image-text encoder, a text generator, and an image generator to extract the most relevant visual and textual representations by optimizing four distinctive loss functions (ITM, ITC, ITG, TIG). Right: self-attention masking strategies for different learning objectives. Bottom: detailed learning objectives. Integrating visual and textual information enables deep fusion through cross-modal interaction and allows each modality to be processed independently for uni-modal generation.
                </div>
            </div>

            <h2 class="section-title">Results & Performance</h2>
            <div class="results-section">
                <p>MedUnifier demonstrates <span class="highlight">state-of-the-art performance</span> across multiple medical imaging tasks:</p>

                <ul style="margin: 1rem 0; padding-left: 2rem;">
                    <li><strong>Uni-modal Tasks:</strong> Superior performance on medical image classification and report generation</li>
                    <li><strong>Cross-modal Tasks:</strong> Enhanced image-text retrieval and matching capabilities</li>
                    <li><strong>Multi-modal Tasks:</strong> Comprehensive understanding and generation across multiple medical imaging modalities</li>
                    <li><strong>Generation Quality:</strong> High-fidelity medical image synthesis guided by textual descriptions</li>
                </ul>

                <p>The model's ability to both understand and generate medical content positions it as a significant advancement toward an <span class="highlight">"all-in-one" VLP model</span> for medical applications.</p>
            </div>

            <!-- Results figure -->
            <div class="results-figure">
                <img src="imgs/MedUnifier-Figure 3.png" alt="MedUnifier Generated vs Ground Truth Reports" style="max-width: 90%; height: auto; border-radius: 0.5rem; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); display: block; margin: 0 auto;">
                <div class="figure-caption">
                    <strong>Figure 3.</strong> Comparison of ground truth and generated radiology reports reveals strong semantic alignment. In the top figure, both reports describe normal heart size, no pneumothorax or pleural effusion, and a normal cardiomediastinal silhouette, with the generated text adding details on osseous structures/intrathoracic processes. In the bottom figure, both reports align on pneumothorax and cardiomegaly. The same colours denote matched content between the generated sequences and the ground truth report.
                </div>
            </div>

            <h2 class="section-title">Impact & Applications</h2>
            <div class="abstract">
                <p>MedUnifier represents a significant step toward developing comprehensive AI systems for medical imaging that can both analyze and generate medical content. The framework's versatility makes it applicable to various clinical scenarios including:</p>

                <ul style="margin: 1rem 0; padding-left: 2rem;">
                    <li><strong>Medical Report Generation:</strong> Automatic generation of detailed diagnostic reports from medical images</li>
                    <li><strong>Educational Content Creation:</strong> Synthesis of medical images for training and educational purposes</li>
                    <li><strong>Cross-modal Medical Understanding:</strong> Enhanced interpretation of complex medical data across different modalities</li>
                    <li><strong>Clinical Decision Support:</strong> Comprehensive analysis combining visual and textual medical information</li>
                </ul>
            </div>

            <h2 class="section-title">Citation</h2>
            <div style="background: #f8f9fa; padding: 1.5rem; border-radius: 0.5rem; font-family: monospace; font-size: 0.9rem; overflow-x: auto;" class="citation-box">
<pre style="margin: 0; color: #000;">@inproceedings{zhang2025medunifier,
  title={MedUnifier: Unifying Vision-and-Language Pre-training on Medical Data with Vision Generation Task using Discrete Visual Representations},
  author={Zhang, Ziyang and Yu, Yang and Chen, Yucheng and Yang, Xulei and Yeo, Si Yong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={29744--29755},
  year={2025}
}</pre>
            </div>

            <div style="text-align: center; margin: 3rem 0; padding: 2rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 1rem;">
                <h3 style="margin-bottom: 1rem;">Published in CVPR 2025</h3>
                <p style="margin: 0; font-size: 1.1rem;">IEEE/CVF Conference on Computer Vision and Pattern Recognition</p>
            </div>
        </div>
    </main>

    <footer class="bg-theme-light dark:bg-darkmode-theme-light">
        <div class="container">
            <div class="row items-center py-10">
                <div class="lg:col-3 mb-8 text-center lg:mb-0 lg:text-left">
                    <a class="navbar-brand inline-block" href="../">
                        <img fetchpriority="high" decoding="async" class="img logo-light" width="160" height="32"
                            src="../imgs/logo_hu1e0a0ed9ef631b29b11507eedded13fb_83803_320x0_resize_q90_h2_lanczos_3.webp"
                            alt="MedVisAITechnologies"
                            onerror='this.onerror=null,this.src="../imgs/logo_hu1e0a0ed9ef631b29b11507eedded13fb_83803_320x0_resize_lanczos_3.png"'>
                        <img fetchpriority="high" decoding="async" class="img logo-dark" width="160" height="32"
                            src="../imgs/logo_hu1e0a0ed9ef631b29b11507eedded13fb_83803_320x0_resize_q90_h2_lanczos_3.webp"
                            alt="MedVisAITechnologies"
                            onerror='this.onerror=null,this.src="../imgs/logo_hu1e0a0ed9ef631b29b11507eedded13fb_83803_320x0_resize_lanczos_3.png"'>
                    </a>
                </div>
                <div class="lg:col-6 mb-8 text-center lg:mb-0">
                    <ul>
                        <li class="m-3 inline-block"><a href="../about/">About</a></li>
                        <li class="m-3 inline-block"><a href="../eml">Contact</a></li>
                        <li class="m-3 inline-block"><a href="../location/">Location</a></li>
                    </ul>
                </div>
                <div class="lg:col-3 mb-8 text-center lg:mb-0 lg:mt-0 lg:text-right">
                    <ul class="social-icons">
                        <li><a target="_blank" aria-label="facebook" rel="nofollow noopener" href="https://www.facebook.com/"><i class="fab fa-facebook"></i></a></li>
                        <li><a target="_blank" aria-label="twitter" rel="nofollow noopener" href="https://twitter.com/"><i class="fab fa-twitter"></i></a></li>
                        <li><a target="_blank" aria-label="github" rel="nofollow noopener" href="https://www.github.com/"><i class="fab fa-github"></i></a></li>
                        <li><a target="_blank" aria-label="linkedin" rel="nofollow noopener" href="https://www.linkedin.com/"><i class="fab fa-linkedin"></i></a></li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="border-border dark:border-darkmode-border border-t py-7">
            <div class="text-light dark:text-darkmode-light container text-center">
                <p></p>
            </div>
        </div>
    </footer>

    <script crossorigin="anonymous" integrity="sha256-HNvx23yefzYJie2GA7dzwBeKevXtramA+LX4E7XFReM="
        src="../js/script.min.1cdbf1db7c9e7f360989ed8603b773c0178a7af5edada980f8b5f813b5c545e3.js"></script>
    <script>"serviceWorker" in navigator && navigator.serviceWorker.register("../service-worker.js")</script>
</body>

</html>